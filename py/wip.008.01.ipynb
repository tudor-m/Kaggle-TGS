{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn --user\n",
    "!pip install sklearn --user\n",
    "!pip install scikit-image --user\n",
    "!pip install tqdm --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input, Dropout, BatchNormalization, Activation, Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "import time\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet_resnet_v8.01.model\n",
      "Unet_resnet_v8.01.csv\n"
     ]
    }
   ],
   "source": [
    "v={'version':008.01}\n",
    "basic_name = \"Unet_resnet_v{version}\".format(**v)\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "4a7f9e82027f04b17b56c177a1831abf25abe2c8"
   },
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def upsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "419fa6e1ad5218241f08f954453fa3899de8e2e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "fc276e696e66de8ab00b68dce1863fa55eb5023d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3e7ff14a5948e2a3190da288d9f29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a2339c6c3b81280839f05269b2314be4541fa5c4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2540f0e31f62450cb80d1e1000c93deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "cbacf34c7506a867795260a9c615cb4427d62c2d"
   },
   "outputs": [],
   "source": [
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "\n",
    "def cov_to_class(val):    \n",
    "    for i in range(0, 11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "c535341361ea08ec77f6821719b7045f308895d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11939eb50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1192a3c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "sns.distplot(train_df.coverage, kde=False, ax=axs[0])\n",
    "sns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\n",
    "plt.suptitle(\"Salt coverage\")\n",
    "axs[0].set_xlabel(\"Coverage\")\n",
    "axs[1].set_xlabel(\"Coverage class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d150fb85dd998ab4dd241c66e52d247ab667dce0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x118199390>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117f7c350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the depth distributions\n",
    "sns.distplot(train_df.z, label=\"Train\")\n",
    "sns.distplot(test_df.z, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.title(\"Depth distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "2ea5c45300c08b06c60548dd09831cff38878551"
   },
   "outputs": [],
   "source": [
    "# Create train/validation split stratified by salt coverage\n",
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = \\\n",
    "train_test_split(train_df.index.values, \n",
    "                 np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1),\n",
    "                 np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1),\n",
    "                 train_df.coverage.values, \n",
    "                 train_df.z.values, \n",
    "                 test_size=0.2, stratify=train_df.coverage_class, random_state=555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "92fe9e2757add49ffb55b4824aa3d833919efde5"
   },
   "outputs": [],
   "source": [
    "def BatchActivate(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    if activation==True: x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16, batch_activate=False):\n",
    "    x = BatchActivate(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3))\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    if batch_activate: x = BatchActivate(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Squeeze-and-Excitation ResNets\n",
    "References:\n",
    "    - [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    "    - []() # added when paper is published on Arxiv\n",
    "'''\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import add\n",
    "from keras.layers import multiply\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import conv_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras import backend as K\n",
    "\n",
    "#from se import squeeze_excite_block\n",
    "\n",
    "__all__ = ['SEResNet', 'SEResNet50', 'SEResNet101', 'SEResNet154', 'preprocess_input', 'decode_predictions']\n",
    "\n",
    "\n",
    "WEIGHTS_PATH = \"\"\n",
    "WEIGHTS_PATH_NO_TOP = \"\"\n",
    "\n",
    "from keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Permute\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def squeeze_excite_block(input, ratio=16):\n",
    "    ''' Create a squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    filters = init._keras_shape[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        se = Permute((3, 1, 2))(se)\n",
    "\n",
    "    x = multiply([init, se])\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def SEResNet(input_shape=None,\n",
    "             initial_conv_filters=64,\n",
    "             depth=[3, 4, 6, 3],\n",
    "             filters=[64, 128, 256, 512],\n",
    "             width=1,\n",
    "             bottleneck=False,\n",
    "             weight_decay=1e-4,\n",
    "             include_top=True,\n",
    "             weights=None,\n",
    "             input_tensor=None,\n",
    "             pooling=None,\n",
    "             classes=1000):\n",
    "    \"\"\" Instantiate the Squeeze and Excite ResNet architecture. Note that ,\n",
    "        when using TensorFlow for best performance you should set\n",
    "        `image_data_format=\"channels_last\"` in your Keras config\n",
    "        at ~/.keras/keras.json.\n",
    "        The model are compatible with both\n",
    "        TensorFlow and Theano. The dimension ordering\n",
    "        convention used by the model is the one\n",
    "        specified in your Keras config file.\n",
    "        # Arguments\n",
    "            initial_conv_filters: number of features for the initial convolution\n",
    "            depth: number or layers in the each block, defined as a list.\n",
    "                ResNet-50  = [3, 4, 6, 3]\n",
    "                ResNet-101 = [3, 6, 23, 3]\n",
    "                ResNet-152 = [3, 8, 36, 3]\n",
    "            filter: number of filters per block, defined as a list.\n",
    "                filters = [64, 128, 256, 512\n",
    "            width: width multiplier for the network (for Wide ResNets)\n",
    "            bottleneck: adds a bottleneck conv to reduce computation\n",
    "            weight_decay: weight decay (l2 norm)\n",
    "            include_top: whether to include the fully-connected\n",
    "                layer at the top of the network.\n",
    "            weights: `None` (random initialization) or `imagenet` (trained\n",
    "                on ImageNet)\n",
    "            input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "                to use as image input for the model.\n",
    "            input_shape: optional shape tuple, only to be specified\n",
    "                if `include_top` is False (otherwise the input shape\n",
    "                has to be `(224, 224, 3)` (with `tf` dim ordering)\n",
    "                or `(3, 224, 224)` (with `th` dim ordering).\n",
    "                It should have exactly 3 inputs channels,\n",
    "                and width and height should be no smaller than 8.\n",
    "                E.g. `(200, 200, 3)` would be one valid value.\n",
    "            pooling: Optional pooling mode for feature extraction\n",
    "                when `include_top` is `False`.\n",
    "                - `None` means that the output of the model will be\n",
    "                    the 4D tensor output of the\n",
    "                    last convolutional layer.\n",
    "                - `avg` means that global average pooling\n",
    "                    will be applied to the output of the\n",
    "                    last convolutional layer, and thus\n",
    "                    the output of the model will be a 2D tensor.\n",
    "                - `max` means that global max pooling will\n",
    "                    be applied.\n",
    "            classes: optional number of classes to classify images\n",
    "                into, only to be specified if `include_top` is True, and\n",
    "                if no `weights` argument is specified.\n",
    "        # Returns\n",
    "            A Keras model instance.\n",
    "        \"\"\"\n",
    "\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    assert len(depth) == len(filters), \"The length of filter increment list must match the length \" \\\n",
    "                                       \"of the depth list.\"\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=32,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=False)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    x = _create_se_resnet(classes, img_input, include_top, initial_conv_filters,\n",
    "                          filters, depth, width, bottleneck, weight_decay, pooling)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnext')\n",
    "\n",
    "    # load weights\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def SEResNet18(input_shape=None,\n",
    "               width=1,\n",
    "               bottleneck=False,\n",
    "               weight_decay=1e-4,\n",
    "               include_top=True,\n",
    "               weights=None,\n",
    "               input_tensor=None,\n",
    "               pooling=None,\n",
    "               classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    depth=[2, 2, 2, 2],\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def SEResNet34(input_shape=None,\n",
    "               width=1,\n",
    "               bottleneck=False,\n",
    "               weight_decay=1e-4,\n",
    "               include_top=True,\n",
    "               weights=None,\n",
    "               input_tensor=None,\n",
    "               pooling=None,\n",
    "               classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    depth=[3, 4, 6, 3],\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def SEResNet50(input_shape=None,\n",
    "               width=1,\n",
    "               bottleneck=True,\n",
    "               weight_decay=1e-4,\n",
    "               include_top=True,\n",
    "               weights=None,\n",
    "               input_tensor=None,\n",
    "               pooling=None,\n",
    "               classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def SEResNet101(input_shape=None,\n",
    "                width=1,\n",
    "                bottleneck=True,\n",
    "                weight_decay=1e-4,\n",
    "                include_top=True,\n",
    "                weights=None,\n",
    "                input_tensor=None,\n",
    "                pooling=None,\n",
    "                classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    depth=[3, 6, 23, 3],\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def SEResNet154(input_shape=None,\n",
    "                width=1,\n",
    "                bottleneck=True,\n",
    "                weight_decay=1e-4,\n",
    "                include_top=True,\n",
    "                weights=None,\n",
    "                input_tensor=None,\n",
    "                pooling=None,\n",
    "                classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    depth=[3, 8, 36, 3],\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def _resnet_block(input, filters, k=1, strides=(1, 1)):\n",
    "    ''' Adds a pre-activation resnet block without bottleneck layers\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "        strides: strides of the convolution layer\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis)(input)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if strides != (1, 1) or init._keras_shape[channel_axis] != filters * k:\n",
    "        init = Conv2D(filters * k, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "                      use_bias=False, strides=strides)(x)\n",
    "\n",
    "    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False, strides=strides)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False)(x)\n",
    "\n",
    "    # squeeze and excite block\n",
    "    x = squeeze_excite_block(x)\n",
    "\n",
    "    m = add([x, init])\n",
    "    return m\n",
    "\n",
    "\n",
    "def _resnet_bottleneck_block(input, filters, k=1, strides=(1, 1)):\n",
    "    ''' Adds a pre-activation resnet block with bottleneck layers\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "        strides: strides of the convolution layer\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    bottleneck_expand = 4\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis)(input)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if strides != (1, 1) or init._keras_shape[channel_axis] != bottleneck_expand * filters * k:\n",
    "        init = Conv2D(bottleneck_expand * filters * k, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "                      use_bias=False, strides=strides)(x)\n",
    "\n",
    "    x = Conv2D(filters * k, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False, strides=strides)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(bottleneck_expand * filters * k, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False)(x)\n",
    "\n",
    "    # squeeze and excite block\n",
    "    x = squeeze_excite_block(x)\n",
    "\n",
    "    m = add([x, init])\n",
    "    return m\n",
    "\n",
    "\n",
    "def _create_se_resnet(classes, img_input, include_top, initial_conv_filters, filters,\n",
    "                      depth, width, bottleneck, weight_decay, pooling):\n",
    "    '''Creates a SE ResNet model with specified parameters\n",
    "    Args:\n",
    "        initial_conv_filters: number of features for the initial convolution\n",
    "        include_top: Flag to include the last dense layer\n",
    "        filters: number of filters per block, defined as a list.\n",
    "            filters = [64, 128, 256, 512\n",
    "        depth: number or layers in the each block, defined as a list.\n",
    "            ResNet-50  = [3, 4, 6, 3]\n",
    "            ResNet-101 = [3, 6, 23, 3]\n",
    "            ResNet-152 = [3, 8, 36, 3]\n",
    "        width: width multiplier for network (for Wide ResNet)\n",
    "        bottleneck: adds a bottleneck conv to reduce computation\n",
    "        weight_decay: weight_decay (l2 norm)\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "    Returns: a Keras Model\n",
    "    '''\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    N = list(depth)\n",
    "\n",
    "    # block 1 (initial conv block)\n",
    "    x = Conv2D(initial_conv_filters, (7, 7), padding='same', use_bias=False, strides=(2, 2),\n",
    "               kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(img_input)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # block 2 (projection block)\n",
    "    for i in range(N[0]):\n",
    "        if bottleneck:\n",
    "            x = _resnet_bottleneck_block(x, filters[0], width)\n",
    "        else:\n",
    "            x = _resnet_block(x, filters[0], width)\n",
    "\n",
    "    # block 3 - N\n",
    "    for k in range(1, len(N)):\n",
    "        if bottleneck:\n",
    "            x = _resnet_bottleneck_block(x, filters[k], width, strides=(2, 2))\n",
    "        else:\n",
    "            x = _resnet_block(x, filters[k], width, strides=(2, 2))\n",
    "\n",
    "        for i in range(N[k] - 1):\n",
    "            if bottleneck:\n",
    "                x = _resnet_bottleneck_block(x, filters[k], width)\n",
    "            else:\n",
    "                x = _resnet_block(x, filters[k], width)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(classes, use_bias=False, kernel_regularizer=l2(weight_decay),\n",
    "                  activation='softmax')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model with SE\n",
    "def build_model_2(input_layer, start_neurons, DropoutRatio=0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons*1, (3,3), activation=None, padding='same')(input_layer)\n",
    "    conv1 = residual_block(conv1, start_neurons*1)\n",
    "    conv1 = residual_block(conv1, start_neurons*1, True)\n",
    "    pool1 = MaxPooling2D((2,2))(conv1)\n",
    "    pool1 = squeeze_excite_block(pool1, ratio=16)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "    \n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons*2, (3,3), activation=None, padding='same')(pool1)\n",
    "    conv2 = residual_block(conv2, start_neurons*2)\n",
    "    conv2 = residual_block(conv2, start_neurons*2, True)\n",
    "    pool2 = MaxPooling2D((2,2))(conv2)\n",
    "    pool2 = squeeze_excite_block(pool2, ratio=16)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "    \n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons*4, (3,3), activation=None, padding='same')(pool2)\n",
    "    conv3 = residual_block(conv3, start_neurons*4)\n",
    "    conv3 = residual_block(conv3, start_neurons*4, True)\n",
    "    pool3 = MaxPooling2D((2,2))(conv3)\n",
    "    pool3 = squeeze_excite_block(pool3, ratio=16)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "    \n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons*8, (3,3), activation=None, padding='same')(pool3)\n",
    "    conv4 = residual_block(conv4, start_neurons*8)\n",
    "    conv4 = residual_block(conv4, start_neurons*8, True)\n",
    "    pool4 = MaxPooling2D((2,2))(conv4)\n",
    "    pool4 = squeeze_excite_block(pool4, ratio=16)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "    \n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons*16, (3,3), activation=None, padding='same')(pool4)\n",
    "    convm = residual_block(convm, start_neurons*16)\n",
    "    convm = residual_block(convm, start_neurons*16, True)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons*8, (3,3), strides=(2,2), padding='same')(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons*8, (3,3), activation=None, padding='same')(uconv4)\n",
    "    uconv4 = residual_block(uconv4, start_neurons*8)\n",
    "    uconv4 = residual_block(uconv4, start_neurons*8, True)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    deconv3 = Conv2DTranspose(start_neurons*4, (3,3), strides=(2,2), padding='valid')(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])\n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons*4, (3,3), activation=None, padding='same')(uconv3)\n",
    "    uconv3 = residual_block(uconv3, start_neurons*4)\n",
    "    uconv3 = residual_block(uconv3, start_neurons*4, True)\n",
    "    \n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons*2, (3,3), strides=(2,2), padding='same')(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    \n",
    "    uconv2 = Conv2D(start_neurons*2, (3,3), activation=None, padding='same')(uconv2)\n",
    "    uconv2 = residual_block(uconv2, start_neurons*2)\n",
    "    uconv2 = residual_block(uconv2, start_neurons*2, True)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    deconv1 = Conv2DTranspose(start_neurons*1, (3,3), strides=(2,2), padding='valid')(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    \n",
    "    uconv1 = Conv2D(start_neurons*1, (3,3), activation=None, padding='same')(uconv1)\n",
    "    uconv1 = residual_block(uconv1, start_neurons*1)\n",
    "    uconv1 = residual_block(uconv1, start_neurons*1, True)\n",
    "    \n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding='same', activation=None)(uconv1)\n",
    "    output_layer = Activation('sigmoid')(output_layer_noActi)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "e4ee11d11d6a42da26b699cbf9ce5f005de91968"
   },
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    batch_size = A.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch]>0, B[batch]>0\n",
    "        intersection = np.logical_and(t, p)\n",
    "        union = np.logical_or(t, p)\n",
    "        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n",
    "        thresholds = np.arange(0.5, 1, 0.05)\n",
    "        s = []\n",
    "        for thresh in thresholds:\n",
    "            s.append(iou > thresh)\n",
    "        metric.append(np.mean(s))\n",
    "        \n",
    "    return np.mean(metric)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "72fdacfe6a31500522f7d4c6ba858120b93bc39d"
   },
   "outputs": [],
   "source": [
    "# code download from: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.elu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "3a4ffe206d6ea50da3d8ccb8ec8d219a2e6cca94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 101, 101, 1)\n",
      "(800, 101, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "#Data augmentation - 2\n",
       "x_train = np.append(x_train, [np.flipud(x) for x in x_train], axis=0)\n",
       "y_train = np.append(y_train, [np.flipud(x) for x in y_train], axis=0)\n",
       "print(x_train.shape)\n",
       "print(y_valid.shape)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data augmentation - 2\n",
    "x_train = np.append(x_train, [np.flipud(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.flipud(x) for x in y_train], axis=0)\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 101, 101, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_776 (Conv2D)             (None, 101, 101, 16) 160         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_756 (BatchN (None, 101, 101, 16) 64          conv2d_776[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_756 (Activation)     (None, 101, 101, 16) 0           batch_normalization_756[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_777 (Conv2D)             (None, 101, 101, 16) 2320        activation_756[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_757 (BatchN (None, 101, 101, 16) 64          conv2d_777[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_757 (Activation)     (None, 101, 101, 16) 0           batch_normalization_757[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_778 (Conv2D)             (None, 101, 101, 16) 2320        activation_757[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_251 (Add)                   (None, 101, 101, 16) 0           conv2d_778[0][0]                 \n",
      "                                                                 conv2d_776[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_758 (BatchN (None, 101, 101, 16) 64          add_251[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_758 (Activation)     (None, 101, 101, 16) 0           batch_normalization_758[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_779 (Conv2D)             (None, 101, 101, 16) 2320        activation_758[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_759 (BatchN (None, 101, 101, 16) 64          conv2d_779[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_759 (Activation)     (None, 101, 101, 16) 0           batch_normalization_759[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_780 (Conv2D)             (None, 101, 101, 16) 2320        activation_759[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_252 (Add)                   (None, 101, 101, 16) 0           conv2d_780[0][0]                 \n",
      "                                                                 add_251[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_760 (BatchN (None, 101, 101, 16) 64          add_252[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_760 (Activation)     (None, 101, 101, 16) 0           batch_normalization_760[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 50, 50, 16)   0           activation_760[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_256 (G (None, 16)           0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_251 (Reshape)           (None, 1, 1, 16)     0           global_average_pooling2d_256[0][0\n",
      "__________________________________________________________________________________________________\n",
      "dense_506 (Dense)               (None, 1, 1, 1)      16          reshape_251[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_507 (Dense)               (None, 1, 1, 16)     16          dense_506[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_251 (Multiply)         (None, 50, 50, 16)   0           max_pooling2d_6[0][0]            \n",
      "                                                                 dense_507[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 50, 16)   0           multiply_251[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_781 (Conv2D)             (None, 50, 50, 32)   4640        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_761 (BatchN (None, 50, 50, 32)   128         conv2d_781[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_761 (Activation)     (None, 50, 50, 32)   0           batch_normalization_761[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_782 (Conv2D)             (None, 50, 50, 32)   9248        activation_761[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_762 (BatchN (None, 50, 50, 32)   128         conv2d_782[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_762 (Activation)     (None, 50, 50, 32)   0           batch_normalization_762[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_783 (Conv2D)             (None, 50, 50, 32)   9248        activation_762[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_253 (Add)                   (None, 50, 50, 32)   0           conv2d_783[0][0]                 \n",
      "                                                                 conv2d_781[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_763 (BatchN (None, 50, 50, 32)   128         add_253[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_763 (Activation)     (None, 50, 50, 32)   0           batch_normalization_763[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_784 (Conv2D)             (None, 50, 50, 32)   9248        activation_763[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_764 (BatchN (None, 50, 50, 32)   128         conv2d_784[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_764 (Activation)     (None, 50, 50, 32)   0           batch_normalization_764[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_785 (Conv2D)             (None, 50, 50, 32)   9248        activation_764[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_254 (Add)                   (None, 50, 50, 32)   0           conv2d_785[0][0]                 \n",
      "                                                                 add_253[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_765 (BatchN (None, 50, 50, 32)   128         add_254[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_765 (Activation)     (None, 50, 50, 32)   0           batch_normalization_765[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 25, 25, 32)   0           activation_765[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 25, 25, 32)   0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_786 (Conv2D)             (None, 25, 25, 64)   18496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_766 (BatchN (None, 25, 25, 64)   256         conv2d_786[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_766 (Activation)     (None, 25, 25, 64)   0           batch_normalization_766[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_787 (Conv2D)             (None, 25, 25, 64)   36928       activation_766[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_767 (BatchN (None, 25, 25, 64)   256         conv2d_787[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_767 (Activation)     (None, 25, 25, 64)   0           batch_normalization_767[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_788 (Conv2D)             (None, 25, 25, 64)   36928       activation_767[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_255 (Add)                   (None, 25, 25, 64)   0           conv2d_788[0][0]                 \n",
      "                                                                 conv2d_786[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_768 (BatchN (None, 25, 25, 64)   256         add_255[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_768 (Activation)     (None, 25, 25, 64)   0           batch_normalization_768[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_789 (Conv2D)             (None, 25, 25, 64)   36928       activation_768[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_769 (BatchN (None, 25, 25, 64)   256         conv2d_789[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_769 (Activation)     (None, 25, 25, 64)   0           batch_normalization_769[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_790 (Conv2D)             (None, 25, 25, 64)   36928       activation_769[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_256 (Add)                   (None, 25, 25, 64)   0           conv2d_790[0][0]                 \n",
      "                                                                 add_255[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_770 (BatchN (None, 25, 25, 64)   256         add_256[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_770 (Activation)     (None, 25, 25, 64)   0           batch_normalization_770[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 12, 12, 64)   0           activation_770[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 12, 12, 64)   0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_791 (Conv2D)             (None, 12, 12, 128)  73856       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_771 (BatchN (None, 12, 12, 128)  512         conv2d_791[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_771 (Activation)     (None, 12, 12, 128)  0           batch_normalization_771[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_792 (Conv2D)             (None, 12, 12, 128)  147584      activation_771[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_772 (BatchN (None, 12, 12, 128)  512         conv2d_792[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_772 (Activation)     (None, 12, 12, 128)  0           batch_normalization_772[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_793 (Conv2D)             (None, 12, 12, 128)  147584      activation_772[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_257 (Add)                   (None, 12, 12, 128)  0           conv2d_793[0][0]                 \n",
      "                                                                 conv2d_791[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_773 (BatchN (None, 12, 12, 128)  512         add_257[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_773 (Activation)     (None, 12, 12, 128)  0           batch_normalization_773[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_794 (Conv2D)             (None, 12, 12, 128)  147584      activation_773[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_774 (BatchN (None, 12, 12, 128)  512         conv2d_794[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_774 (Activation)     (None, 12, 12, 128)  0           batch_normalization_774[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_795 (Conv2D)             (None, 12, 12, 128)  147584      activation_774[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_258 (Add)                   (None, 12, 12, 128)  0           conv2d_795[0][0]                 \n",
      "                                                                 add_257[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_775 (BatchN (None, 12, 12, 128)  512         add_258[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_775 (Activation)     (None, 12, 12, 128)  0           batch_normalization_775[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 6, 6, 128)    0           activation_775[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 6, 6, 128)    0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_796 (Conv2D)             (None, 6, 6, 256)    295168      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_776 (BatchN (None, 6, 6, 256)    1024        conv2d_796[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_776 (Activation)     (None, 6, 6, 256)    0           batch_normalization_776[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_797 (Conv2D)             (None, 6, 6, 256)    590080      activation_776[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_777 (BatchN (None, 6, 6, 256)    1024        conv2d_797[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_777 (Activation)     (None, 6, 6, 256)    0           batch_normalization_777[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_798 (Conv2D)             (None, 6, 6, 256)    590080      activation_777[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_259 (Add)                   (None, 6, 6, 256)    0           conv2d_798[0][0]                 \n",
      "                                                                 conv2d_796[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_778 (BatchN (None, 6, 6, 256)    1024        add_259[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_778 (Activation)     (None, 6, 6, 256)    0           batch_normalization_778[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_799 (Conv2D)             (None, 6, 6, 256)    590080      activation_778[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_779 (BatchN (None, 6, 6, 256)    1024        conv2d_799[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_779 (Activation)     (None, 6, 6, 256)    0           batch_normalization_779[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_800 (Conv2D)             (None, 6, 6, 256)    590080      activation_779[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_260 (Add)                   (None, 6, 6, 256)    0           conv2d_800[0][0]                 \n",
      "                                                                 add_259[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_780 (BatchN (None, 6, 6, 256)    1024        add_260[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_780 (Activation)     (None, 6, 6, 256)    0           batch_normalization_780[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 12, 12, 128)  295040      activation_780[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 12, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_775[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 12, 12, 256)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_801 (Conv2D)             (None, 12, 12, 128)  295040      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_781 (BatchN (None, 12, 12, 128)  512         conv2d_801[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_781 (Activation)     (None, 12, 12, 128)  0           batch_normalization_781[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_802 (Conv2D)             (None, 12, 12, 128)  147584      activation_781[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_782 (BatchN (None, 12, 12, 128)  512         conv2d_802[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_782 (Activation)     (None, 12, 12, 128)  0           batch_normalization_782[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_803 (Conv2D)             (None, 12, 12, 128)  147584      activation_782[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_261 (Add)                   (None, 12, 12, 128)  0           conv2d_803[0][0]                 \n",
      "                                                                 conv2d_801[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_783 (BatchN (None, 12, 12, 128)  512         add_261[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_783 (Activation)     (None, 12, 12, 128)  0           batch_normalization_783[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_804 (Conv2D)             (None, 12, 12, 128)  147584      activation_783[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_784 (BatchN (None, 12, 12, 128)  512         conv2d_804[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_784 (Activation)     (None, 12, 12, 128)  0           batch_normalization_784[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_805 (Conv2D)             (None, 12, 12, 128)  147584      activation_784[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_262 (Add)                   (None, 12, 12, 128)  0           conv2d_805[0][0]                 \n",
      "                                                                 add_261[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_785 (BatchN (None, 12, 12, 128)  512         add_262[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_785 (Activation)     (None, 12, 12, 128)  0           batch_normalization_785[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 25, 25, 64)   73792       activation_785[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 25, 25, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_770[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 25, 25, 128)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_806 (Conv2D)             (None, 25, 25, 64)   73792       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_786 (BatchN (None, 25, 25, 64)   256         conv2d_806[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_786 (Activation)     (None, 25, 25, 64)   0           batch_normalization_786[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_807 (Conv2D)             (None, 25, 25, 64)   36928       activation_786[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_787 (BatchN (None, 25, 25, 64)   256         conv2d_807[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_787 (Activation)     (None, 25, 25, 64)   0           batch_normalization_787[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_808 (Conv2D)             (None, 25, 25, 64)   36928       activation_787[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_263 (Add)                   (None, 25, 25, 64)   0           conv2d_808[0][0]                 \n",
      "                                                                 conv2d_806[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_788 (BatchN (None, 25, 25, 64)   256         add_263[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_788 (Activation)     (None, 25, 25, 64)   0           batch_normalization_788[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_809 (Conv2D)             (None, 25, 25, 64)   36928       activation_788[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_789 (BatchN (None, 25, 25, 64)   256         conv2d_809[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_789 (Activation)     (None, 25, 25, 64)   0           batch_normalization_789[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_810 (Conv2D)             (None, 25, 25, 64)   36928       activation_789[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_264 (Add)                   (None, 25, 25, 64)   0           conv2d_810[0][0]                 \n",
      "                                                                 add_263[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_790 (BatchN (None, 25, 25, 64)   256         add_264[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_790 (Activation)     (None, 25, 25, 64)   0           batch_normalization_790[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 50, 50, 32)   18464       activation_790[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 50, 50, 64)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_765[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 50, 50, 64)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_811 (Conv2D)             (None, 50, 50, 32)   18464       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_791 (BatchN (None, 50, 50, 32)   128         conv2d_811[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_791 (Activation)     (None, 50, 50, 32)   0           batch_normalization_791[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_812 (Conv2D)             (None, 50, 50, 32)   9248        activation_791[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_792 (BatchN (None, 50, 50, 32)   128         conv2d_812[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_792 (Activation)     (None, 50, 50, 32)   0           batch_normalization_792[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_813 (Conv2D)             (None, 50, 50, 32)   9248        activation_792[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_265 (Add)                   (None, 50, 50, 32)   0           conv2d_813[0][0]                 \n",
      "                                                                 conv2d_811[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_793 (BatchN (None, 50, 50, 32)   128         add_265[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_793 (Activation)     (None, 50, 50, 32)   0           batch_normalization_793[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_814 (Conv2D)             (None, 50, 50, 32)   9248        activation_793[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_794 (BatchN (None, 50, 50, 32)   128         conv2d_814[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_794 (Activation)     (None, 50, 50, 32)   0           batch_normalization_794[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_815 (Conv2D)             (None, 50, 50, 32)   9248        activation_794[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_266 (Add)                   (None, 50, 50, 32)   0           conv2d_815[0][0]                 \n",
      "                                                                 add_265[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_795 (BatchN (None, 50, 50, 32)   128         add_266[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_795 (Activation)     (None, 50, 50, 32)   0           batch_normalization_795[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 101, 101, 16) 4624        activation_795[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 101, 101, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_760[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 101, 101, 32) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_816 (Conv2D)             (None, 101, 101, 16) 4624        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_796 (BatchN (None, 101, 101, 16) 64          conv2d_816[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_796 (Activation)     (None, 101, 101, 16) 0           batch_normalization_796[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_817 (Conv2D)             (None, 101, 101, 16) 2320        activation_796[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_797 (BatchN (None, 101, 101, 16) 64          conv2d_817[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_797 (Activation)     (None, 101, 101, 16) 0           batch_normalization_797[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_818 (Conv2D)             (None, 101, 101, 16) 2320        activation_797[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_267 (Add)                   (None, 101, 101, 16) 0           conv2d_818[0][0]                 \n",
      "                                                                 conv2d_816[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_798 (BatchN (None, 101, 101, 16) 64          add_267[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_798 (Activation)     (None, 101, 101, 16) 0           batch_normalization_798[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_819 (Conv2D)             (None, 101, 101, 16) 2320        activation_798[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_799 (BatchN (None, 101, 101, 16) 64          conv2d_819[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_799 (Activation)     (None, 101, 101, 16) 0           batch_normalization_799[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_820 (Conv2D)             (None, 101, 101, 16) 2320        activation_799[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_268 (Add)                   (None, 101, 101, 16) 0           conv2d_820[0][0]                 \n",
      "                                                                 add_267[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_800 (BatchN (None, 101, 101, 16) 64          add_268[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_800 (Activation)     (None, 101, 101, 16) 0           batch_normalization_800[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_821 (Conv2D)             (None, 101, 101, 1)  17          activation_800[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_801 (Activation)     (None, 101, 101, 1)  0           conv2d_821[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 5,119,889\n",
      "Trainable params: 5,112,529\n",
      "Non-trainable params: 7,360\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model_2(input_layer, 16,0.5)\n",
    "\n",
    "model1 = Model(input_layer, output_layer)\n",
    "\n",
    "c = optimizers.adam(lr = 0.005)\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n",
    "\n",
    "model1.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d2a007cc2bb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                      \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                      \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                      verbose = 2)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mt_model2_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/user/Library/Python/2.7/lib/python/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/user/Library/Python/2.7/lib/python/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/user/Library/Python/2.7/lib/python/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2474\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2476\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2478\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[0;32m/Users/user/Library/Python/2.7/lib/python/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 192\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/user/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/user/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/user/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/user/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/user/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1312\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m/Users/user/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m             tf_session.TF_ExtendGraph(self._session,\n\u001b[0;32m-> 1358\u001b[0;31m                                       graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1359\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mSerializeToString\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m           'Message %s is missing required fields: %s' % (\n\u001b[1;32m   1041\u001b[0m           self.DESCRIPTOR.full_name, ','.join(self.FindInitializationErrors())))\n\u001b[0;32m-> 1042\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerializeToString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mSerializePartialToString\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mInternalSerialize\u001b[0;34m(self, write_bytes, deterministic)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m         \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0mwrite_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/google/protobuf/internal/encoder.pyc\u001b[0m in \u001b[0;36mEncodeRepeatedField\u001b[0;34m(write, value, deterministic)\u001b[0m\n\u001b[1;32m    757\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0mlocal_EncodeVarint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mEncodeRepeatedField\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mByteSize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1017\u001b[0m       \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields_by_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mListFields\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mListFields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m     \u001b[0mall_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_IsPresent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m     \u001b[0mall_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',patience=15, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name, monitor='my_iou_metric', mode='max',\n",
    "                                   save_best_only=True, verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode='max', factor=0.5, patience=5,\n",
    "                              min_lr=0.00005, verbose=1)\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 128\n",
    "\n",
    "t_model1_start = time.time()\n",
    "history = model1.fit(x_train, y_train,\n",
    "                     validation_data = [x_valid, y_valid], \n",
    "                     epochs = epochs, \n",
    "                     batch_size = batch_size, \n",
    "                     callbacks = [early_stopping, model_checkpoint, reduce_lr],\n",
    "                     verbose = 2)\n",
    "t_model1_end = time.time()\n",
    "\n",
    "v={\"tt\":(t_model1_end-t_model1_start)/3600}\n",
    "print(\"Run time = {(tt} hours\".format(**v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "52ba1ba40cac42145f499cff252eb73feff397d3"
   },
   "outputs": [],
   "source": [
    "model1 = load_model(save_model_name, custom_objects={'my_iou_metric':my_iou_metric})\n",
    "# remove activation layer and use lovasz loss\n",
    "input_x = model1.layers[0].input\n",
    "\n",
    "output_layer = model1.layers[-1].input\n",
    "model = Model(input_x, output_layer)\n",
    "c = optimizers.adam(lr=0.01)\n",
    "\n",
    "model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec1e49fd425a02ab12dea6b99cf39de45c80199f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=30, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=10, \n",
    "                              min_lr=0.00005, verbose=1)\n",
    "epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "t_model2_start = time.time()\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[ model_checkpoint,reduce_lr,early_stopping], \n",
    "                    verbose=2)\n",
    "t_model2_end = time.time()\n",
    "print(f\"Run time = {(t_model2_end-t_model2_start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "922febde76d7aff93c49c71a28b3a2361f433d02"
   },
   "outputs": [],
   "source": [
    "fig, (ax_loss, ax_score) = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax_loss.legend()\n",
    "ax_score.plot(history.epoch, history.history[\"my_iou_metric_2\"], label=\"Train score\")\n",
    "ax_score.plot(history.epoch, history.history[\"val_my_iou_metric_2\"], label=\"Validation score\")\n",
    "ax_score.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "068c89f56e9e7eb1d7ecf12912996426ad87f2a6"
   },
   "outputs": [],
   "source": [
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "                                                   'lovasz_loss': lovasz_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c33f2cdf50d3011f704ac934e49602bd3167c8cb"
   },
   "outputs": [],
   "source": [
    "def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n",
    "    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n",
    "    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test += np.array([ np.fliplr(x) for x in preds_test2_refect] )\n",
    "    return preds_test/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec38f74adccf2d265cac160311c0998fefc76ec6"
   },
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6794a936dd110f0d4ecc23206c53af7cd0f4a587"
   },
   "outputs": [],
   "source": [
    "#Score the model and do a threshold optimization by the best IoU.\n",
    "\n",
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "\n",
    "\n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n",
    "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
    "#     temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))\n",
    "    #print(temp1)\n",
    "    intersection = temp1[0]\n",
    "    #print(\"temp2 = \",temp1[1])\n",
    "    #print(intersection.shape)\n",
    "   # print(intersection)\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    #print(np.histogram(labels, bins = true_objects))\n",
    "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
    "    #print(\"area_true = \",area_true)\n",
    "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "  \n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    intersection[intersection == 0] = 1e-9\n",
    "    \n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "        \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d96072932f985336021cd115cb6bb13058618a8"
   },
   "outputs": [],
   "source": [
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce197d87cf44fef681025160cba8e4081d15ed50"
   },
   "outputs": [],
   "source": [
    "threshold_best_index = np.argmax(ious)\n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, 'xr', label='Best threshold')\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2633e0c50ddb705021a35441c6a19fae9312603e"
   },
   "outputs": [],
   "source": [
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1-mask, 0-background\n",
    "    Returns run length as string\n",
    "    '''\n",
    "    pixels = im.flatten(order='F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c29b25a37ceb7476bc0264ea3a97dc705e07607"
   },
   "outputs": [],
   "source": [
    "x_test = np.array([(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e129e7c3e525b884322570ed37da825cd89db290"
   },
   "outputs": [],
   "source": [
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aac939d180585abab6dd497a45f81e3df67b25a8"
   },
   "outputs": [],
   "source": [
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d6ef314f368bf9923285007e7098c068af049d9"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae636758e7abdc7fb87768cbfb2c6f18f8c1975f"
   },
   "outputs": [],
   "source": [
    "t_finish = time.time()\n",
    "print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76d50b9d2159775ae3a84336ef0c01cbcf39a18e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
