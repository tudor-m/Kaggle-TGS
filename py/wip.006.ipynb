{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "4cac5e4652a641fac2e64b12537feeb5746cf512"
   },
   "outputs": [],
   "source": [
    "# wip.006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fa525d982fdb7e518de47cd8ec52f6ee868d312b"
   },
   "source": [
    "## Update\n",
    "- Use UpSample2d+Conv2d instead of ConvTrans2D, see comments for detail\n",
    "- Add Batch Normalization layer after each conv\n",
    "- You can use crf method (https://www.kaggle.com/meaninglesslives/apply-crf) to improve the result \n",
    "## Changelog\n",
    "- Changed uncov to uconv, but removed the dropout in the last layer\n",
    "- Corrected sanity check of predicted validation data (changed from ids_train to ids_valid)\n",
    "- Used correct mask (from original train_df) for threshold tuning (inserted y_valid_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "77e05df3218e009eafa91b1afffbb5cdd6535a41"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ada861a85e9549dca27667692da408c5fdccbaa5"
   },
   "source": [
    "# About\n",
    "Since I am new to learning from image segmentation and kaggle in general I want to share my noteook.\n",
    "I saw it is similar to others as it uses the U-net approach. I want to share it anyway because:\n",
    "\n",
    "- As said, the field is new to me so I am open to suggestions.\n",
    "- It visualizes some of the steps, e.g. scaling, to learn if the methods do what I expect which might be useful to others (I call them sanity checks).\n",
    "- Added stratification by the amount of salt contained in the image.\n",
    "- Added augmentation by flipping the images along the y axes (thanks to the forum for clarification).\n",
    "- Added dropout to the model which seems to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rotate\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\n",
    "from keras.layers import Conv2D, Concatenate, MaxPooling2D\n",
    "from keras.layers import UpSampling2D, Dropout, BatchNormalization\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "#import pydensecrf.densecrf as dcrf\n",
    "from skimage.color import gray2rgb\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.io import imread, imsave, imshow\n",
    "#from pydensecrf.utils import unary_from_labels, create_pairwise_bilateral\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "962c2c6775b5fcf605df8e7c59cbcabe6ba9ceaa"
   },
   "source": [
    "# Params and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e54e151245d665e42bb95d9cf2e1a33cb9440e48"
   },
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 128\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    #res = np.zeros((img_size_target, img_size_target), dtype=img.dtype)\n",
    "    #res[:img_size_ori, :img_size_ori] = img\n",
    "    #return res\n",
    "    \n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "    #return img[:img_size_ori, :img_size_ori]\n",
    "    \n",
    "def img_mask_plot(img,mask):\n",
    "    fix, axs = plt.subplots(1, 2, figsize=(10,10))\n",
    "    axs[0].imshow(img.squeeze(), cmap=\"Greys\")\n",
    "    axs[0].set_title(\"Image\")\n",
    "\n",
    "    axs[1].imshow(mask.squeeze(), cmap=\"Greys\")\n",
    "    axs[1].set_title(\"Mask\")\n",
    "    \n",
    "def img_3_plot(img1,img2,img3,tit=\"\",tits=[\"Img1\",\"Img2\",\"Img3\"]):\n",
    "    fix, axs = plt.subplots(1, 3, figsize=(8,8))\n",
    "    fix.suptitle(tit,fontsize=10)\n",
    "    axs[0].imshow(img1.squeeze(), cmap=\"Greys\")\n",
    "    axs[0].set_title(tits[0])\n",
    "    axs[1].imshow(img2.squeeze(), cmap=\"Greys\")\n",
    "    axs[1].set_title(tits[1])\n",
    "    axs[2].imshow(img3.squeeze(), cmap=\"Greys\")\n",
    "    axs[2].set_title(tits[2])\n",
    "    fix.subplots_adjust(top=1.5)\n",
    "    plt.show()\n",
    "\n",
    "def img_4_plot(img1,img2,img3,img4,tit=\"\",tits=[\"Img1\",\"Img2\",\"Img3\",\"Img4\"]):\n",
    "    fix, axs = plt.subplots(1, 4, figsize=(8,8))\n",
    "    fix.suptitle(tit,fontsize=10)\n",
    "    axs[0].imshow(img1.squeeze(), cmap=\"Greys\")\n",
    "    axs[0].set_title(tits[0])\n",
    "    axs[1].imshow(img2.squeeze(), cmap=\"Greys\")\n",
    "    axs[1].set_title(tits[1])\n",
    "    axs[2].imshow(img3.squeeze(), cmap=\"Greys\")\n",
    "    axs[2].set_title(tits[2])\n",
    "    axs[3].imshow(img4.squeeze(), cmap=\"Greys\")\n",
    "    axs[3].set_title(tits[3])\n",
    "    fix.subplots_adjust(top=1.5)\n",
    "    plt.show()\n",
    "\n",
    "def img_5_plot(img1,img2,img3,img4,img5,tit=\"\",tits=[\"Img1\",\"Img2\",\"Img3\",\"Img4\",\"Img5\"]):\n",
    "    fix, axs = plt.subplots(1, 5, figsize=(8,8))\n",
    "    fix.suptitle(tit,fontsize=10)\n",
    "    axs[0].imshow(img1.squeeze(), cmap=\"Greys\")\n",
    "    axs[0].set_title(tits[0])\n",
    "    axs[1].imshow(img2.squeeze(), cmap=\"Greys\")\n",
    "    axs[1].set_title(tits[1])\n",
    "    axs[2].imshow(img3.squeeze(), cmap=\"Greys\")\n",
    "    axs[2].set_title(tits[2])\n",
    "    axs[3].imshow(img4.squeeze(), cmap=\"Greys\")\n",
    "    axs[3].set_title(tits[3])\n",
    "    axs[4].imshow(img5.squeeze(), cmap=\"Greys\")\n",
    "    axs[4].set_title(tits[4])\n",
    "    fix.subplots_adjust(top=1.5)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def iou_clean_old(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return iou\n",
    "\n",
    "def iou_clean(y_true_in, y_pred_in):\n",
    "    intr = np.sum((y_true_in+y_pred_in)==2)\n",
    "    unio = np.sum(y_true_in+y_pred_in)-intr\n",
    "    if unio == 0:\n",
    "        ret = 1\n",
    "    else:\n",
    "        ret = intr/unio\n",
    "    return ret\n",
    "\n",
    "def prec_clean(y_true_in, y_pred_in):\n",
    "    tp = np.sum((y_true_in+y_pred_in)==2)\n",
    "    fp = np.sum(y_true_in == (y_pred_in+1))\n",
    "    fn = np.sum(y_true_in == (y_pred_in-1))\n",
    "    sum_p = tp+fp+fn\n",
    "    if sum_p == 0:\n",
    "        pr = 1\n",
    "    else:\n",
    "        pr = tp/sum_p\n",
    "    return pr\n",
    "    \n",
    "\n",
    "def iou_clean_batch(y_true_in, y_pred_in):\n",
    "    import numpy as np\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_clean(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.array(metric)\n",
    "\n",
    "def prec_clean_batch(y_true_in, y_pred_in):\n",
    "    import numpy as np\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    prec = []\n",
    "    for batch in range(batch_size):\n",
    "        value = prec_clean(y_true_in[batch], y_pred_in[batch])\n",
    "        prec.append(value)\n",
    "    return np.array(prec)\n",
    "\n",
    "\n",
    "def error_estimation_batch(true_mask,pred_mask):\n",
    "    ious = iou_clean_batch(true_mask,pred_mask)\n",
    "    precs= prec_clean_batch(true_mask,pred_mask)\n",
    "    coefs = np.zeros(ious.shape)\n",
    "    coefs[ious>=0.50] = 0.1\n",
    "    coefs[ious>=0.55] = 0.2\n",
    "    coefs[ious>=0.60] = 0.3\n",
    "    coefs[ious>=0.65] = 0.4\n",
    "    coefs[ious>=0.70] = 0.5\n",
    "    coefs[ious>=0.75] = 0.6\n",
    "    coefs[ious>=0.80] = 0.7\n",
    "    coefs[ious>=0.85] = 0.8\n",
    "    coefs[ious>=0.90] = 0.9\n",
    "    coefs[ious>=0.95] = 1.0\n",
    "    value = np.mean(precs*coefs)\n",
    "    return value\n",
    "\n",
    "# Source https://www.kaggle.com/bguberfain/unet-with-depth\n",
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31511499d3f16e6a484b0effbf213dc45755d651"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function which returns the labelled image after applying CRF\n",
    "\n",
    "\"\"\"\n",
    "#Original_image = Image which has to labelled\n",
    "#Mask image = Which has been labelled by some technique..\n",
    "def crf(original_image, mask_img, gt_prob=0.7, steps = 10):\n",
    "    \n",
    "    # Converting annotated image to RGB if it is Gray scale\n",
    "    if(len(mask_img.shape)<3):\n",
    "        mask_img = gray2rgb(mask_img)\n",
    "\n",
    "#     #Converting the annotations RGB color to single 32 bit integer\n",
    "#    annotated_label = mask_img[:,:,0] + (mask_img[:,:,1]<<8) + (mask_img[:,:,2]<<16)\n",
    "    annotated_label = mask_img[:,:,0] + (np.int64(mask_img[:,:,1])<<8) + (np.int64(mask_img[:,:,2])<<16)\n",
    "\n",
    "    \n",
    "#     # Convert the 32bit integer color to 0,1, 2, ... labels.\n",
    "    colors, labels = np.unique(annotated_label, return_inverse=True)\n",
    "\n",
    "    n_labels = 2\n",
    "    \n",
    "    #Setting up the CRF model\n",
    "    d = dcrf.DenseCRF2D(original_image.shape[1], original_image.shape[0], n_labels)\n",
    "\n",
    "    # get unary potentials (neg log probability)\n",
    "    U = unary_from_labels(labels, n_labels, gt_prob, zero_unsure=False)\n",
    "    d.setUnaryEnergy(U)\n",
    "\n",
    "    # This adds the color-independent term, features are the locations only.\n",
    "    d.addPairwiseGaussian(sxy=(3, 3), compat=3, kernel=dcrf.DIAG_KERNEL,\n",
    "                      normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "        \n",
    "    #Run Inference for (10) steps \n",
    "    Q = d.inference(steps)\n",
    "\n",
    "    # Find out the most probable class for each pixel.\n",
    "    MAP = np.argmax(Q, axis=0)\n",
    "\n",
    "    return MAP.reshape((original_image.shape[0],original_image.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformations:\n",
    "def warp_an_image(im_in,n1=6,n2=6):\n",
    "#    from skimage.transform import PiecewiseAffineTransform, warp, resize\n",
    "#    import skimage.util\n",
    "\n",
    "    rows,cols = im_in.shape[0], im_in.shape[1]\n",
    "    im_in_rows = np.linspace(0, cols, 20)\n",
    "    im_in_cols = np.linspace(0, rows, 10)\n",
    "    src_rows, src_cols = np.meshgrid(im_in_rows, im_in_cols)\n",
    "\n",
    "    src = np.dstack([src_cols.flat, src_rows.flat])[0]\n",
    "\n",
    "    # add sinusoidal oscillation to row coordinates:\n",
    "    dst_rows = src[:, 1] - np.sin(np.linspace(0, n2 * np.pi, src.shape[0])) * n1\n",
    "    dst_cols = src[:, 0]\n",
    "\n",
    "    #dst_rows *= 1.\n",
    "    #dst_rows -= 1. * n1\n",
    "    dst = np.vstack([dst_cols, dst_rows]).T\n",
    "\n",
    "    tform = PiecewiseAffineTransform()\n",
    "    tform.estimate(src, dst)\n",
    "\n",
    "    out_rows = im_in.shape[0]# - 1. * n1\n",
    "    out_cols = cols\n",
    "    out = warp(im_in, tform, output_shape=(out_rows, out_cols))\n",
    "    out = out[15:85,15:85]\n",
    "    out = resize(out,(128,128))\n",
    "    \n",
    "    return out\n",
    "\n",
    "def get_a_tform(im_in,n1=6,n2=6):\n",
    "    from skimage.transform import PiecewiseAffineTransform, warp, resize\n",
    "    import skimage.util\n",
    "\n",
    "    rows,cols = im_in.shape[0], im_in.shape[1]\n",
    "    im_in_rows = np.linspace(0, cols, 20)\n",
    "    im_in_cols = np.linspace(0, rows, 10)\n",
    "    src_rows, src_cols = np.meshgrid(im_in_rows, im_in_cols)\n",
    "\n",
    "    src = np.dstack([src_cols.flat, src_rows.flat])[0]\n",
    "\n",
    "    # add sinusoidal oscillation to row coordinates:\n",
    "    dst_rows = src[:, 1] - np.sin(np.linspace(0, n2 * np.pi, src.shape[0])) * n1\n",
    "    dst_cols = src[:, 0]\n",
    "\n",
    "    #dst_rows *= 1.\n",
    "    #dst_rows -= 1. * n1\n",
    "    dst = np.vstack([dst_cols, dst_rows]).T\n",
    "\n",
    "    tform = PiecewiseAffineTransform()\n",
    "    tform.estimate(src, dst)\n",
    "    return tform\n",
    "    \n",
    "def warp_an_image_fast(im_in,tfrm,out_cols,out_rows):\n",
    "    from skimage.transform import warp\n",
    "    out = warp(im_in, tform, output_shape=(out_rows, out_cols))\n",
    "    out = out[15:85,15:85]\n",
    "    out = resize(out,(128,128))\n",
    "    return out    \n",
    "    \n",
    "def swirl_an_image(im_in):\n",
    "    from skimage.transform import swirl,resize\n",
    "    out = swirl(im_in,strength=2)\n",
    "    out = resize(out,(128,128))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "530c358f2868a444e8233936996463a66c2cc4f3"
   },
   "source": [
    "# Loading of training/testing ids and depths\n",
    "Reading the training data and the depths, store them in a DataFrame. Also create a test DataFrame with entries from depth not in train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "24d7f3d982bfa582b222f012129acdda55282b6d"
   },
   "source": [
    "# Read images and masks\n",
    "Load the images and masks into the DataFrame and divide the pixel values by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b18c1f50cefd7504eae7e7b9605be3814c7cad6d"
   },
   "outputs": [],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86620c6a070571895f4f36ec050a25803915ed74"
   },
   "outputs": [],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad64a6689bb53e4a66febb80875dacc75f892599"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1137f0a009f10b5f69e4dade5f689e744e9ce1d6"
   },
   "source": [
    "# Calculating the salt coverage and salt coverage classes\n",
    "Counting the number of salt pixels in the masks and dividing them by the image size. Also create 11 coverage classes, -0.1 having no salt at all to 1.0 being salt only.\n",
    "Plotting the distribution of coverages and coverage classes, and the class against the raw coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18d2aa182a44c65a87c75f41047c653a79bc1c3f"
   },
   "outputs": [],
   "source": [
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b13d1ecc7004832e8e042d034922796263054b7"
   },
   "outputs": [],
   "source": [
    "n_cl = 10\n",
    "def cov_to_class(val):    \n",
    "    for i in range(0, 1+n_cl):\n",
    "        if val * n_cl <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a5e66ff4809ea2f9a679b7ddbda5028dc324137a"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "sns.distplot(train_df.coverage, kde=False, ax=axs[0])\n",
    "sns.distplot(train_df.coverage_class, bins=n_cl, kde=False, ax=axs[1])\n",
    "plt.suptitle(\"Salt coverage\")\n",
    "axs[0].set_xlabel(\"Coverage\")\n",
    "axs[1].set_xlabel(\"Coverage class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0dd39993eb2c7e77e5ce2d3388ea8ff1d581a670"
   },
   "outputs": [],
   "source": [
    "plt.scatter(train_df.coverage, train_df.coverage_class)\n",
    "plt.xlabel(\"Coverage\")\n",
    "plt.ylabel(\"Coverage class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2391c568019151b098a002937516bb77a506f403"
   },
   "source": [
    "# Plotting the depth distributions\n",
    "Separatelty plotting the depth distributions for the training and the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6ae7b7011b7de3caed58f9ca3939df15ffa319ad"
   },
   "outputs": [],
   "source": [
    "sns.distplot(train_df.z, label=\"Train\")\n",
    "sns.distplot(test_df.z, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.title(\"Depth distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14835b3e0eafd3a1c0e3a1f18a2e7979e75d3fa3"
   },
   "source": [
    "# Show some example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7fbfda6fb7c54bf483593d50732ce7603ab98049"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1a6bc85ee458f72c0917edf77895d5abc5eaf3ee",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_images = 20\n",
    "grid_width = 10\n",
    "plot_class = 1\n",
    "grid_height = int(max_images / grid_width)\n",
    "fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n",
    "#for i, idx in enumerate(train_df[train_df.coverage_class==plot_class].index[:max_images]):\n",
    "for i, idx in enumerate(train_df.index[:max_images]):\n",
    "    img = train_df.loc[idx].images\n",
    "    mask = train_df.loc[idx].masks\n",
    "    ax = axs[int(i / grid_width), i % grid_width]\n",
    "    ax.imshow(img, cmap=\"Greys\")\n",
    "    ax.imshow(mask, alpha=0.3, cmap=\"Reds\")\n",
    "    ax.text(1, img_size_ori-1, train_df.loc[idx].z, color=\"black\")\n",
    "    ax.text(img_size_ori - 1, 1, round(train_df.loc[idx].coverage, 2), color=\"black\", ha=\"right\", va=\"top\")\n",
    "    ax.text(1, 1, train_df.loc[idx].coverage_class, color=\"black\", ha=\"left\", va=\"top\")\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "plt.suptitle(\"Green: salt. Top-left: coverage class, top-right: salt coverage, bottom-left: depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52a77e4cc0d2b42c74d7cd9b0756a10c794c07c4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "00655e32f93f96ebd90dbe94e35ee052f52217cd"
   },
   "source": [
    "# Create train/validation split stratified by salt coverage\n",
    "Using the salt coverage as a stratification criterion. Also show an image to check for correct upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d3c3157512d11e71ac74ce51a937b85bedfe1d1"
   },
   "outputs": [],
   "source": [
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_valid, depth_train, depth_valid = train_test_split(\n",
    "    train_df.index.values,\n",
    "    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    train_df.coverage.values,\n",
    "    train_df.z.values,\n",
    "    test_size=0.2, stratify=train_df.coverage_class, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Split information\n",
    "pd.DataFrame(ids_train,columns=[\"ids_train\"]).to_csv(\"ids_train.csv\")\n",
    "pd.DataFrame(ids_valid,columns=[\"ids_valid\"]).to_csv(\"ids_valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Split information and re-build the data from train_df\n",
    "ids_train = np.array(pd.read_csv(\"ids_train.csv\").ids_train)\n",
    "ids_valid = np.array(pd.read_csv(\"ids_valid.csv\").ids_valid)\n",
    "\n",
    "x_train = np.array(train_df.loc[ids_train][\"images\"].map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n",
    "y_train = np.array(train_df.loc[ids_train][\"masks\"].map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n",
    "cov_train = train_df[train_df.index.isin(ids_train)][\"coverage\"].values\n",
    "depth_train = train_df[train_df.index.isin(ids_train)][\"z\"].values\n",
    "\n",
    "x_valid = np.array(train_df.loc[ids_valid][\"images\"].map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n",
    "y_valid = np.array(train_df.loc[ids_valid][\"masks\"].map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n",
    "cov_valid = train_df[train_df.index.isin(ids_valid)][\"coverage\"].values\n",
    "depth_valid = train_df[train_df.index.isin(ids_valid)][\"z\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f2f1ab00f03e71e6d7f9b2214408b5a9779fc235"
   },
   "outputs": [],
   "source": [
    "tmp_idx = 30\n",
    "tmp_img = np.zeros((img_size_target, img_size_target), dtype=train_df.images.loc[ids_train[tmp_idx]].dtype)\n",
    "tmp_img[:img_size_ori, :img_size_ori] = train_df.images.loc[ids_train[tmp_idx]]\n",
    "\n",
    "\n",
    "fix, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "axs[0].imshow(tmp_img, cmap=\"Greys\")\n",
    "axs[0].set_title(\"Original image\")\n",
    "\n",
    "axs[1].imshow(x_train[tmp_idx].squeeze(), cmap=\"Greys\")\n",
    "axs[1].set_title(\"Upsampled image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "63ac58ab47921b4e4f54102e2c8b85fa318225f1"
   },
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1aa78bd7c607e1f0e0235e4b2f82056c0361dac5"
   },
   "outputs": [],
   "source": [
    "def conv_block(m, dim, acti, bn, res, do=0):\n",
    "\tn = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
    "\tn = BatchNormalization()(n) if bn else n\n",
    "\tn = Dropout(do)(n) if do else n\n",
    "\tn = Conv2D(dim, 3, activation=acti, padding='same')(n)\n",
    "\tn = BatchNormalization()(n) if bn else n\n",
    "\treturn Concatenate()([m, n]) if res else n\n",
    "\n",
    "def level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):\n",
    "\tif depth > 0:\n",
    "\t\tn = conv_block(m, dim, acti, bn, res)\n",
    "\t\tm = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n",
    "\t\tm = level_block(m, int(inc*dim), depth-1, inc, acti, do, bn, mp, up, res)\n",
    "\t\tif up:\n",
    "\t\t\tm = UpSampling2D()(m)\n",
    "\t\t\tm = Conv2D(dim, 2, activation=acti, padding='same')(m)\n",
    "\t\telse:\n",
    "\t\t\tm = Conv2DTranspose(dim, 3, strides=2, activation=acti, padding='same')(m)\n",
    "\t\tn = Concatenate()([n, m])\n",
    "\t\tm = conv_block(n, dim, acti, bn, res)\n",
    "\telse:\n",
    "\t\tm = conv_block(m, dim, acti, bn, res, do)\n",
    "\treturn m\n",
    "\n",
    "def UNet(img_shape, out_ch=1, start_ch=64, depth=4, inc_rate=2., activation='relu', \n",
    "\t\t dropout=0.5, batchnorm=False, maxpool=True, upconv=True, residual=False):\n",
    "\ti = Input(shape=img_shape)\n",
    "\to = level_block(i, start_ch, depth, inc_rate, activation, dropout, batchnorm, maxpool, upconv, residual)\n",
    "\to = Conv2D(out_ch, 1, activation='sigmoid')(o)\n",
    "\treturn Model(inputs=i, outputs=o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2382b088c8a6be16490354ebd386120a9ced414d"
   },
   "outputs": [],
   "source": [
    "model = UNet((img_size_target,img_size_target,1),start_ch=16,depth=5,batchnorm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3399029adb039b049e3d6ca01fef30ed8653482b"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7ded4adc1757c88a1bea59ea36b1a9f7941bd28"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c007157c2fd3d7dadcaeee2a6376351852d1e565"
   },
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8618a66a11d998f072f8cc6fc696e332321ed1ae"
   },
   "outputs": [],
   "source": [
    "x_train_bak = x_train.copy()\n",
    "y_train_bak = y_train.copy()\n",
    "depth_train_back = depth_train.copy()\n",
    "cov_train_back = cov_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf85501608db1cc1562ccba314bbfc0b53f004f0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "88b3f57eac3ec3719b401730dc6d8d2d89d09ccc"
   },
   "outputs": [],
   "source": [
    "# Augment with left-right flips\n",
    "x_train = np.append(x_train, [np.fliplr(y) for y in x_train_bak], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(y) for y in y_train_bak], axis=0)\n",
    "depth_train = np.append(depth_train,depth_train_back,axis=0)\n",
    "cov_train = np.append(cov_train,cov_train_back,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d068eb7e8f8c92d5fc2297bd1b8b16333f45e37b"
   },
   "outputs": [],
   "source": [
    "# Augment with warp\n",
    "from skimage.transform import PiecewiseAffineTransform, warp, resize\n",
    "import skimage.util\n",
    "\n",
    "x_train = np.append(x_train, [warp_an_image(y) for y in x_train_bak], axis=0)\n",
    "y_train = np.append(y_train, [warp_an_image(y) for y in y_train_bak], axis=0)\n",
    "depth_train = np.append(depth_train,depth_train_back,axis=0)\n",
    "cov_train = np.append(cov_train,cov_train_back,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bak[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bak.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1437f902962ae7dd965a04f8097babcd3824c035"
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7040f72549212dd4f71c13dfbd8bf013481ea369"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 10, figsize=(15,3))\n",
    "for i in range(10):\n",
    "    axs[0][i].imshow(x_train[i].squeeze(), cmap=\"Blues\")\n",
    "    axs[0][i].imshow(y_train[i].squeeze(), cmap=\"Reds\", alpha=0.3)\n",
    "    axs[1][i].imshow(x_train[int(len(x_train_bak) + i)].squeeze(), cmap=\"Blues\")\n",
    "    axs[1][i].imshow(y_train[int(len(y_train_bak) + i)].squeeze(), cmap=\"Reds\", alpha=0.3)\n",
    "    axs[2][i].imshow(x_train[2*int(len(x_train_bak)) +i].squeeze(), cmap=\"Blues\")\n",
    "    axs[2][i].imshow(y_train[2*int(len(y_train_bak)) +i].squeeze(), cmap=\"Reds\", alpha=0.3)\n",
    "fig.suptitle(\"Top row: original images, bottom row: augmented images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5a6b1abaa4681cba3b608bc5f33cf260370d82a"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f1773642758da7b4480e0e48c045bd01ea3684ae",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"./keras.wip.005.model\", save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early_stopping, model_checkpoint, reduce_lr],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42e9ef3c4e0a2bb2539e5e51740ba6bfc092d37c"
   },
   "outputs": [],
   "source": [
    "fig, (ax_loss, ax_acc) = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax_acc.plot(history.epoch, history.history[\"acc\"], label=\"Train accuracy\")\n",
    "ax_acc.plot(history.epoch, history.history[\"val_acc\"], label=\"Validation accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a8157ae760a44160a3b1dc9867683c1a277c6f8a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c824f6bca47f051500966c433ce7fb5a9528f6d7"
   },
   "outputs": [],
   "source": [
    "model = load_model(\"../submissions/0.737/keras.wip.005.model\")\n",
    "#model = load_model(\"../submissions/0.758/keras.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0f168318eadb324daa8c020f0e3e0a24d82a464f"
   },
   "source": [
    "# Predict the masks, use Validation 1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "16cbfe2fee11a8b13b96ce78161ce19b5e5a0c46"
   },
   "outputs": [],
   "source": [
    "preds_valid = model.predict(x_valid).reshape(-1, img_size_target, img_size_target)\n",
    "preds_valid = np.array([downsample(x) for x in preds_valid])\n",
    "y_valid_ori = np.array([train_df.loc[idx].masks for idx in ids_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b9d00b05a3d513df7954432c886152ecfee3c5f0"
   },
   "outputs": [],
   "source": [
    "# Plot some random images\n",
    "for val_idx in range(4):\n",
    "    img_3_plot(x_valid[val_idx],preds_valid[val_idx],y_valid[val_idx],tit=\"val_idx=\"+str(val_idx),\\\n",
    "              tits=[\"image\",\"prediction\",\"truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b1198b6fb7369c3cfb70e68cd1b78d36aa188bc"
   },
   "outputs": [],
   "source": [
    "# Plot more images\n",
    "max_images = 60\n",
    "grid_width = 15\n",
    "grid_height = int(max_images / grid_width)\n",
    "fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n",
    "for i, idx in enumerate(ids_valid[:max_images]):\n",
    "    img = train_df.loc[idx].images\n",
    "    mask = train_df.loc[idx].masks\n",
    "    pred = preds_valid[i]\n",
    "    ax = axs[int(i / grid_width), i % grid_width]\n",
    "    ax.imshow(img, cmap=\"Greys\")\n",
    "    ax.imshow(mask, alpha=0.3, cmap=\"Greens\")\n",
    "    ax.imshow(pred, alpha=0.3, cmap=\"OrRd\")\n",
    "    ax.text(1, img_size_ori-1, train_df.loc[idx].z, color=\"black\")\n",
    "    ax.text(img_size_ori - 1, 1, round(train_df.loc[idx].coverage, 2), color=\"black\", ha=\"right\", va=\"top\")\n",
    "    ax.text(1, 1, train_df.loc[idx].coverage_class, color=\"black\", ha=\"left\", va=\"top\")\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "plt.suptitle(\"Green: salt, Red: prediction. Top-left: coverage class, top-right: salt coverage, bottom-left: depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd973023204ebf921fe1f23748856e6a6f692aa4",
    "collapsed": true
   },
   "source": [
    "# Determine the best 0/1 threshold, use Validation 1 dataset\n",
    "Use the contest metrics against the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_array = []\n",
    "err_array = []\n",
    "ious_array  = []\n",
    "for thr in np.arange(0.0,1.0,0.005):\n",
    "    pred_mask_thr = np.array(np.round(preds_valid > thr), dtype=np.float32)\n",
    "    err = error_estimation_batch(true_mask=y_valid_ori, pred_mask=pred_mask_thr)\n",
    "    ious = iou_clean_batch(y_pred_in=pred_mask_thr,y_true_in=y_valid_ori)\n",
    "    cov_pred = np.sum(np.sum(pred_mask_thr,axis=1),axis=1)/101**2\n",
    "    low_ious_cnt = np.sum(ious<0.5)\n",
    "    low_ious_cnt_low_cov = np.sum(np.logical_and(ious<0.5,cov_pred<0.5))\n",
    "    print(thr,err,low_ious_cnt,low_ious_cnt_low_cov)\n",
    "    thr_array.append(thr)\n",
    "    err_array.append(err)\n",
    "    ious_array.append(ious) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1:\n",
    "# Fixed threshold:\n",
    "threshold_best = thr_array[np.argmax(err_array)]\n",
    "err_best       = err_array[np.argmax(err_array)]\n",
    "iou_best       = ious_array[np.argmax(err_array)]\n",
    "pred_mask_thr = np.array(np.round(preds_valid > 1.0*threshold_best), dtype=np.float32)\n",
    "err = error_estimation_batch(true_mask=y_valid_ori, pred_mask=pred_mask_thr)\n",
    "cov_pred = np.sum(np.sum(pred_mask_thr,axis=1),axis=1)/101**2\n",
    "\n",
    "print(\"threshold_best: \",threshold_best)\n",
    "print(\"error_best: \",err_best)\n",
    "print(\"err: \",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2:\n",
    "# Vector threshold:\n",
    "# Build the variable vector threshold:\n",
    "threshold_best_array = np.full(preds_valid.shape[0],threshold_best)\n",
    "# Override the best threshold for low salt coverage predictions:\n",
    "cov_pred = np.sum(np.sum(pred_mask_thr,axis=1),axis=1)/101**2\n",
    "threshold_best_array[cov_pred<0.5] = 0.6\n",
    "\n",
    "# Buid the mask: \n",
    "pred_mask_thr = [preds_valid[x] > threshold_best_array[x] for x in range(preds_valid.shape[0])]\n",
    "\n",
    "# Re-calculate the error\n",
    "err = error_estimation_batch(true_mask=y_valid_ori, pred_mask=pred_mask_thr)\n",
    "err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thr_array, err_array)\n",
    "plt.plot(threshold_best, err_best, \"sr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "#plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU with threshold:\n",
    "ious = iou_clean_batch(y_pred_in=pred_mask_thr,y_true_in=y_valid_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ious.shape,depth_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_pred = np.sum(np.sum(pred_mask_thr,axis=1),axis=1)/101**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU vs. depth\n",
    "plt.plot(depth_valid,ious,'db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU vs. salt coverage\n",
    "plt.plot(cov_valid,ious,'db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cov_valid,ious,'db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cov_pred,cov_valid,'db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(ious<=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val_idx in np.where(ious<=0.1)[0]:\n",
    "    img_4_plot(x_valid[val_idx],preds_valid[val_idx],pred_mask_thr[val_idx],y_valid[val_idx],\\\n",
    "               tit=\"val_idx=\"+str(val_idx),tits=[\"img\",\"pred\",\"pred_thr\",\"true\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Prediction and Error Evaluation, Validation 1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = model.predict(x_valid).reshape(-1, img_size_target, img_size_target)\n",
    "preds_valid = np.array([downsample(x) for x in preds_valid])\n",
    "y_valid_ori = np.array([train_df.loc[idx].masks for idx in ids_valid])\n",
    "pred_mask_thr = np.array(np.round(preds_valid > threshold_best), dtype=np.float32)\n",
    "err = error_estimation_batch(true_mask=y_valid_ori, pred_mask=pred_mask_thr)\n",
    "print(\"error=\",err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Prediction and Error Evaluation, Validation 2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid_2 = model.predict(x_valid_2).reshape(-1, img_size_target, img_size_target)\n",
    "preds_valid_2 = np.array([downsample(x) for x in preds_valid_2])\n",
    "y_valid_ori_2 = np.empty((0,101,101))\n",
    "y_valid_ori_2 = np.append(y_valid_ori_2,[rotate(y,30) for y in y_valid_ori],axis=0)\n",
    "pred_mask_thr_2 = np.array(np.round(preds_valid_2 > threshold_best), dtype=np.float32)\n",
    "err_2 = error_estimation_batch(true_mask=downsample(y_valid_ori_2), pred_mask=pred_mask_thr_2)\n",
    "print(err_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Have a look in the 2nd validation dataset - if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val_idx in range(50):\n",
    "    img_4_plot(x_valid_2[val_idx],preds_valid_2[val_idx],pred_mask_thr_2[val_idx],y_valid_2[val_idx],tit=\"val_idx=\"+str(val_idx),\\\n",
    "              tits=[\"img\",\"prediction\",\"prediction_thr\",\"truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "423b3268c580dc1eae84f54deeeb0f691eff6028"
   },
   "source": [
    "# Adjusted threshold\n",
    "Again some sample images with the adjusted threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40c263765ac6d53a8c0c1361ff1e6f061eecf825"
   },
   "outputs": [],
   "source": [
    "max_images = 30\n",
    "grid_width = 15\n",
    "grid_height = int(max_images / grid_width)\n",
    "fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n",
    "for i, idx in enumerate(ids_valid[:max_images]):\n",
    "    img = train_df.loc[idx].images\n",
    "    mask = train_df.loc[idx].masks\n",
    "    pred = preds_valid[i]\n",
    "    ax = axs[int(i / grid_width), i % grid_width]\n",
    "    ax.imshow(img, cmap=\"Greys\")\n",
    "    ax.imshow(mask, alpha=0.3, cmap=\"Greens\")\n",
    "    ax.imshow(np.array(np.round(pred > threshold_best), dtype=np.float32), alpha=0.3, cmap=\"OrRd\")\n",
    "    ax.text(1, img_size_ori-1, train_df.loc[idx].z, color=\"black\")\n",
    "    ax.text(img_size_ori - 1, 1, round(train_df.loc[idx].coverage, 2), color=\"black\", ha=\"right\", va=\"top\")\n",
    "    ax.text(1, 1, train_df.loc[idx].coverage_class, color=\"black\", ha=\"left\", va=\"top\")\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "plt.suptitle(\"Green: salt, Red: prediction. Top-left: coverage class, top-right: salt coverage, bottom-left: depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Processing\n",
    "CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some visualisation:\n",
    "for val_idx in range(0,20):\n",
    "    img1 = x_valid[val_idx][:,:,0]\n",
    "    img1 = np.int64(np.round(img1*255))\n",
    "    img2 = upsample(preds_valid[val_idx])\n",
    "    #img3 = np.round(img2 > threshold_best)\n",
    "    img3 = np.round(upsample(pred_mask_thr[val_idx]))\n",
    "    img4 = y_valid[val_idx][:,:,0]\n",
    "    img5 = crf(img1,img3,gt_prob=0.66)\n",
    "    img_5_plot(img1,img2,img3,img4,img5,tit=\"val_idx=\"+str(val_idx),\\\n",
    "               tits=[\"img\",\"pred_mask\",\"pred_mask_thresh\",\"true_mask\",\"pred_mask_crf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for steps in np.arange(8,15,1):\n",
    "    for gt in np.arange(0.66,0.74,0.02):\n",
    "        pred_mask_thr_crf = []\n",
    "        for y in range(len(ids_valid)):\n",
    "            img1 = downsample(x_valid[y][:,:,0])\n",
    "            img1 = np.int64(np.round(img1*255))\n",
    "            img2 = preds_valid[y]\n",
    "            img3 = np.round((pred_mask_thr[y]))\n",
    "            pred_mask_thr_crf.append((crf(img1,img3,gt_prob=gt,steps=steps)))\n",
    "        print(steps,gt,\":\",error_estimation_batch(true_mask=y_valid_ori, pred_mask=pred_mask_thr_crf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_best = 0.68\n",
    "steps_best = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Submission\n",
    "Create a validation submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = model.predict(x_valid).reshape(-1, img_size_target, img_size_target)\n",
    "valid_dict  = {idx: RLenc(np.round(downsample(preds_valid[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "sub = pd.DataFrame.from_dict(valid_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('submission.valid.wip.005.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Post-Processing\n",
    "CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "332a614c0ae837c115ec6563f355753ffbb8cd83"
   },
   "source": [
    "# Submission\n",
    "Load, predict and submit the test image predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ecb152b492c7126d12c5ef2c701eec8ea3d86f1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_test = np.array([upsample(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale=True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f278d0b87320c117b4ed7c116a991782b82ba5a7"
   },
   "outputs": [],
   "source": [
    "preds_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "113f816f9db8b87ca7f6845fe6e61328ab606f41"
   },
   "outputs": [],
   "source": [
    "pred_dict = {idx: RLenc(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4243166f91c4bcb4da00208f4f53dd912dbb429f"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('submission.wip.005.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd6ce9b4d5fc80a2502a43e80299d628fb5ffc42"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
