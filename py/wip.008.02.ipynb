{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn --user\n",
    "!pip install sklearn --user\n",
    "!pip install scikit-image --user\n",
    "!pip install tqdm --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input, Dropout, BatchNormalization, Activation, Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "import time\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "v={'version':008.01}\n",
    "basic_name = \"Unet_resnet_v{version}\".format(**v)\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a7f9e82027f04b17b56c177a1831abf25abe2c8"
   },
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def upsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "419fa6e1ad5218241f08f954453fa3899de8e2e7"
   },
   "outputs": [],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fc276e696e66de8ab00b68dce1863fa55eb5023d"
   },
   "outputs": [],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a2339c6c3b81280839f05269b2314be4541fa5c4"
   },
   "outputs": [],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cbacf34c7506a867795260a9c615cb4427d62c2d"
   },
   "outputs": [],
   "source": [
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "\n",
    "def cov_to_class(val):    \n",
    "    for i in range(0, 11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c535341361ea08ec77f6821719b7045f308895d3"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "sns.distplot(train_df.coverage, kde=False, ax=axs[0])\n",
    "sns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\n",
    "plt.suptitle(\"Salt coverage\")\n",
    "axs[0].set_xlabel(\"Coverage\")\n",
    "axs[1].set_xlabel(\"Coverage class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d150fb85dd998ab4dd241c66e52d247ab667dce0"
   },
   "outputs": [],
   "source": [
    "#Plotting the depth distributionsÂ¶\n",
    "sns.distplot(train_df.z, label=\"Train\")\n",
    "sns.distplot(test_df.z, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.title(\"Depth distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ea5c45300c08b06c60548dd09831cff38878551"
   },
   "outputs": [],
   "source": [
    "# Create train/validation split stratified by salt coverage\n",
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = \\\n",
    "train_test_split(train_df.index.values, \n",
    "                 np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1),\n",
    "                 np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1),\n",
    "                 train_df.coverage.values, \n",
    "                 train_df.z.values, \n",
    "                 test_size=0.2, stratify=train_df.coverage_class, random_state=555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "92fe9e2757add49ffb55b4824aa3d833919efde5"
   },
   "outputs": [],
   "source": [
    "def BatchActivate(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    if activation==True: x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16, batch_activate=False):\n",
    "    x = BatchActivate(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3))\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    if batch_activate: x = BatchActivate(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import add\n",
    "from keras.layers import multiply\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import conv_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.engine.topology import get_source_inputs\n",
    "#from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras import backend as K\n",
    "\n",
    "#from se import squeeze_excite_block\n",
    "\n",
    "__all__ = ['SEResNet', 'SEResNet50', 'SEResNet101', 'SEResNet154', 'preprocess_input', 'decode_predictions']\n",
    "\n",
    "\n",
    "WEIGHTS_PATH = \"\"\n",
    "WEIGHTS_PATH_NO_TOP = \"\"\n",
    "\n",
    "from keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Permute\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def squeeze_excite_block(input, ratio=16):\n",
    "    ''' Create a squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    filters = init._keras_shape[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        se = Permute((3, 1, 2))(se)\n",
    "\n",
    "    x = multiply([init, se])\n",
    "    return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "'''\n",
    "Squeeze-and-Excitation ResNets\n",
    "References:\n",
    "    - [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    "    - []() # added when paper is published on Arxiv\n",
    "'''\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import add\n",
    "from keras.layers import multiply\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import conv_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras import backend as K\n",
    "\n",
    "#from se import squeeze_excite_block\n",
    "\n",
    "__all__ = ['SEResNet', 'SEResNet50', 'SEResNet101', 'SEResNet154', 'preprocess_input', 'decode_predictions']\n",
    "\n",
    "\n",
    "WEIGHTS_PATH = \"\"\n",
    "WEIGHTS_PATH_NO_TOP = \"\"\n",
    "\n",
    "from keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Permute\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def squeeze_excite_block(input, ratio=16):\n",
    "    ''' Create a squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    filters = init._keras_shape[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        se = Permute((3, 1, 2))(se)\n",
    "\n",
    "    x = multiply([init, se])\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def SEResNet(input_shape=None,\n",
    "             initial_conv_filters=64,\n",
    "             depth=[3, 4, 6, 3],\n",
    "             filters=[64, 128, 256, 512],\n",
    "             width=1,\n",
    "             bottleneck=False,\n",
    "             weight_decay=1e-4,\n",
    "             include_top=True,\n",
    "             weights=None,\n",
    "             input_tensor=None,\n",
    "             pooling=None,\n",
    "             classes=1000):\n",
    "    \"\"\" Instantiate the Squeeze and Excite ResNet architecture. Note that ,\n",
    "        when using TensorFlow for best performance you should set\n",
    "        `image_data_format=\"channels_last\"` in your Keras config\n",
    "        at ~/.keras/keras.json.\n",
    "        The model are compatible with both\n",
    "        TensorFlow and Theano. The dimension ordering\n",
    "        convention used by the model is the one\n",
    "        specified in your Keras config file.\n",
    "        # Arguments\n",
    "            initial_conv_filters: number of features for the initial convolution\n",
    "            depth: number or layers in the each block, defined as a list.\n",
    "                ResNet-50  = [3, 4, 6, 3]\n",
    "                ResNet-101 = [3, 6, 23, 3]\n",
    "                ResNet-152 = [3, 8, 36, 3]\n",
    "            filter: number of filters per block, defined as a list.\n",
    "                filters = [64, 128, 256, 512\n",
    "            width: width multiplier for the network (for Wide ResNets)\n",
    "            bottleneck: adds a bottleneck conv to reduce computation\n",
    "            weight_decay: weight decay (l2 norm)\n",
    "            include_top: whether to include the fully-connected\n",
    "                layer at the top of the network.\n",
    "            weights: `None` (random initialization) or `imagenet` (trained\n",
    "                on ImageNet)\n",
    "            input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "                to use as image input for the model.\n",
    "            input_shape: optional shape tuple, only to be specified\n",
    "                if `include_top` is False (otherwise the input shape\n",
    "                has to be `(224, 224, 3)` (with `tf` dim ordering)\n",
    "                or `(3, 224, 224)` (with `th` dim ordering).\n",
    "                It should have exactly 3 inputs channels,\n",
    "                and width and height should be no smaller than 8.\n",
    "                E.g. `(200, 200, 3)` would be one valid value.\n",
    "            pooling: Optional pooling mode for feature extraction\n",
    "                when `include_top` is `False`.\n",
    "                - `None` means that the output of the model will be\n",
    "                    the 4D tensor output of the\n",
    "                    last convolutional layer.\n",
    "                - `avg` means that global average pooling\n",
    "                    will be applied to the output of the\n",
    "                    last convolutional layer, and thus\n",
    "                    the output of the model will be a 2D tensor.\n",
    "                - `max` means that global max pooling will\n",
    "                    be applied.\n",
    "            classes: optional number of classes to classify images\n",
    "                into, only to be specified if `include_top` is True, and\n",
    "                if no `weights` argument is specified.\n",
    "        # Returns\n",
    "            A Keras model instance.\n",
    "        \"\"\"\n",
    "\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    assert len(depth) == len(filters), \"The length of filter increment list must match the length \" \\\n",
    "                                       \"of the depth list.\"\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=32,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=False)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    x = _create_se_resnet(classes, img_input, include_top, initial_conv_filters,\n",
    "                          filters, depth, width, bottleneck, weight_decay, pooling)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnext')\n",
    "\n",
    "    # load weights\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def SEResNet18(input_shape=None,\n",
    "               width=1,\n",
    "               bottleneck=False,\n",
    "               weight_decay=1e-4,\n",
    "               include_top=True,\n",
    "               weights=None,\n",
    "               input_tensor=None,\n",
    "               pooling=None,\n",
    "               classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    depth=[2, 2, 2, 2],\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def SEResNet34(input_shape=None,\n",
    "               width=1,\n",
    "               bottleneck=False,\n",
    "               weight_decay=1e-4,\n",
    "               include_top=True,\n",
    "               weights=None,\n",
    "               input_tensor=None,\n",
    "               pooling=None,\n",
    "               classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    depth=[3, 4, 6, 3],\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def SEResNet50(input_shape=None,\n",
    "               width=1,\n",
    "               bottleneck=True,\n",
    "               weight_decay=1e-4,\n",
    "               include_top=True,\n",
    "               weights=None,\n",
    "               input_tensor=None,\n",
    "               pooling=None,\n",
    "               classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def SEResNet101(input_shape=None,\n",
    "                width=1,\n",
    "                bottleneck=True,\n",
    "                weight_decay=1e-4,\n",
    "                include_top=True,\n",
    "                weights=None,\n",
    "                input_tensor=None,\n",
    "                pooling=None,\n",
    "                classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    depth=[3, 6, 23, 3],\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def SEResNet154(input_shape=None,\n",
    "                width=1,\n",
    "                bottleneck=True,\n",
    "                weight_decay=1e-4,\n",
    "                include_top=True,\n",
    "                weights=None,\n",
    "                input_tensor=None,\n",
    "                pooling=None,\n",
    "                classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    depth=[3, 8, 36, 3],\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def _resnet_block(input, filters, k=1, strides=(1, 1)):\n",
    "    ''' Adds a pre-activation resnet block without bottleneck layers\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "        strides: strides of the convolution layer\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis)(input)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if strides != (1, 1) or init._keras_shape[channel_axis] != filters * k:\n",
    "        init = Conv2D(filters * k, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "                      use_bias=False, strides=strides)(x)\n",
    "\n",
    "    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False, strides=strides)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False)(x)\n",
    "\n",
    "    # squeeze and excite block\n",
    "    x = squeeze_excite_block(x)\n",
    "\n",
    "    m = add([x, init])\n",
    "    return m\n",
    "\n",
    "\n",
    "def _resnet_bottleneck_block(input, filters, k=1, strides=(1, 1)):\n",
    "    ''' Adds a pre-activation resnet block with bottleneck layers\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "        strides: strides of the convolution layer\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    bottleneck_expand = 4\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis)(input)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if strides != (1, 1) or init._keras_shape[channel_axis] != bottleneck_expand * filters * k:\n",
    "        init = Conv2D(bottleneck_expand * filters * k, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "                      use_bias=False, strides=strides)(x)\n",
    "\n",
    "    x = Conv2D(filters * k, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False, strides=strides)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(bottleneck_expand * filters * k, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False)(x)\n",
    "\n",
    "    # squeeze and excite block\n",
    "    x = squeeze_excite_block(x)\n",
    "\n",
    "    m = add([x, init])\n",
    "    return m\n",
    "\n",
    "\n",
    "def _create_se_resnet(classes, img_input, include_top, initial_conv_filters, filters,\n",
    "                      depth, width, bottleneck, weight_decay, pooling):\n",
    "    '''Creates a SE ResNet model with specified parameters\n",
    "    Args:\n",
    "        initial_conv_filters: number of features for the initial convolution\n",
    "        include_top: Flag to include the last dense layer\n",
    "        filters: number of filters per block, defined as a list.\n",
    "            filters = [64, 128, 256, 512\n",
    "        depth: number or layers in the each block, defined as a list.\n",
    "            ResNet-50  = [3, 4, 6, 3]\n",
    "            ResNet-101 = [3, 6, 23, 3]\n",
    "            ResNet-152 = [3, 8, 36, 3]\n",
    "        width: width multiplier for network (for Wide ResNet)\n",
    "        bottleneck: adds a bottleneck conv to reduce computation\n",
    "        weight_decay: weight_decay (l2 norm)\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "    Returns: a Keras Model\n",
    "    '''\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    N = list(depth)\n",
    "\n",
    "    # block 1 (initial conv block)\n",
    "    x = Conv2D(initial_conv_filters, (7, 7), padding='same', use_bias=False, strides=(2, 2),\n",
    "               kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(img_input)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # block 2 (projection block)\n",
    "    for i in range(N[0]):\n",
    "        if bottleneck:\n",
    "            x = _resnet_bottleneck_block(x, filters[0], width)\n",
    "        else:\n",
    "            x = _resnet_block(x, filters[0], width)\n",
    "\n",
    "    # block 3 - N\n",
    "    for k in range(1, len(N)):\n",
    "        if bottleneck:\n",
    "            x = _resnet_bottleneck_block(x, filters[k], width, strides=(2, 2))\n",
    "        else:\n",
    "            x = _resnet_block(x, filters[k], width, strides=(2, 2))\n",
    "\n",
    "        for i in range(N[k] - 1):\n",
    "            if bottleneck:\n",
    "                x = _resnet_bottleneck_block(x, filters[k], width)\n",
    "            else:\n",
    "                x = _resnet_block(x, filters[k], width)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(classes, use_bias=False, kernel_regularizer=l2(weight_decay),\n",
    "                  activation='softmax')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model with SE\n",
    "def build_model_2(input_layer, start_neurons, DropoutRatio=0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons*1, (3,3), activation=None, padding='same')(input_layer)\n",
    "    conv1 = residual_block(conv1, start_neurons*1)\n",
    "    conv1 = residual_block(conv1, start_neurons*1, True)\n",
    "    pool1 = MaxPooling2D((2,2))(conv1)\n",
    "    pool1 = squeeze_excite_block(pool1, ratio=16)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "    \n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons*2, (3,3), activation=None, padding='same')(pool1)\n",
    "    conv2 = residual_block(conv2, start_neurons*2)\n",
    "    conv2 = residual_block(conv2, start_neurons*2, True)\n",
    "    pool2 = MaxPooling2D((2,2))(conv2)\n",
    "    pool2 = squeeze_excite_block(pool2, ratio=16)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "    \n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons*4, (3,3), activation=None, padding='same')(pool2)\n",
    "    conv3 = residual_block(conv3, start_neurons*4)\n",
    "    conv3 = residual_block(conv3, start_neurons*4, True)\n",
    "    pool3 = MaxPooling2D((2,2))(conv3)\n",
    "    pool3 = squeeze_excite_block(pool3, ratio=16)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "    \n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons*8, (3,3), activation=None, padding='same')(pool3)\n",
    "    conv4 = residual_block(conv4, start_neurons*8)\n",
    "    conv4 = residual_block(conv4, start_neurons*8, True)\n",
    "    pool4 = MaxPooling2D((2,2))(conv4)\n",
    "    pool4 = squeeze_excite_block(pool4, ratio=16)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "    \n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons*16, (3,3), activation=None, padding='same')(pool4)\n",
    "    convm = residual_block(convm, start_neurons*16)\n",
    "    convm = residual_block(convm, start_neurons*16, True)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons*8, (3,3), strides=(2,2), padding='same')(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons*8, (3,3), activation=None, padding='same')(uconv4)\n",
    "    uconv4 = residual_block(uconv4, start_neurons*8)\n",
    "    uconv4 = residual_block(uconv4, start_neurons*8, True)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    deconv3 = Conv2DTranspose(start_neurons*4, (3,3), strides=(2,2), padding='valid')(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])\n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons*4, (3,3), activation=None, padding='same')(uconv3)\n",
    "    uconv3 = residual_block(uconv3, start_neurons*4)\n",
    "    uconv3 = residual_block(uconv3, start_neurons*4, True)\n",
    "    \n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons*2, (3,3), strides=(2,2), padding='same')(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    \n",
    "    uconv2 = Conv2D(start_neurons*2, (3,3), activation=None, padding='same')(uconv2)\n",
    "    uconv2 = residual_block(uconv2, start_neurons*2)\n",
    "    uconv2 = residual_block(uconv2, start_neurons*2, True)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    deconv1 = Conv2DTranspose(start_neurons*1, (3,3), strides=(2,2), padding='valid')(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    \n",
    "    uconv1 = Conv2D(start_neurons*1, (3,3), activation=None, padding='same')(uconv1)\n",
    "    uconv1 = residual_block(uconv1, start_neurons*1)\n",
    "    uconv1 = residual_block(uconv1, start_neurons*1, True)\n",
    "    \n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding='same', activation=None)(uconv1)\n",
    "    output_layer = Activation('sigmoid')(output_layer_noActi)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e4ee11d11d6a42da26b699cbf9ce5f005de91968"
   },
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    batch_size = A.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch]>0, B[batch]>0\n",
    "        intersection = np.logical_and(t, p)\n",
    "        union = np.logical_or(t, p)\n",
    "        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n",
    "        thresholds = np.arange(0.5, 1, 0.05)\n",
    "        s = []\n",
    "        for thresh in thresholds:\n",
    "            s.append(iou > thresh)\n",
    "        metric.append(np.mean(s))\n",
    "        \n",
    "    return np.mean(metric)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72fdacfe6a31500522f7d4c6ba858120b93bc39d"
   },
   "outputs": [],
   "source": [
    "# code download from: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.elu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a4ffe206d6ea50da3d8ccb8ec8d219a2e6cca94"
   },
   "outputs": [],
   "source": [
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation - 2\n",
    "x_train = np.append(x_train, [np.flipud(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.flipud(x) for x in y_train], axis=0)\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "#output_layer = build_model_2(input_layer, 16,0.5)\n",
    "output_layer = build_model_2(input_layer, 32,0.5)\n",
    "\n",
    "model1 = Model(input_layer, output_layer)\n",
    "\n",
    "c = optimizers.adam(lr = 0.005)\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n",
    "\n",
    "model1.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',patience=30, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name, monitor='my_iou_metric', mode='max',\n",
    "                                   save_best_only=True, verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode='max', factor=0.5, patience=15,\n",
    "                              min_lr=0.00005, verbose=1)\n",
    "\n",
    "epochs = 600\n",
    "batch_size = 128\n",
    "\n",
    "t_model1_start = time.time()\n",
    "history = model1.fit(x_train, y_train,\n",
    "                     validation_data = [x_valid, y_valid], \n",
    "                     epochs = epochs, \n",
    "                     batch_size = batch_size, \n",
    "                     callbacks = [early_stopping, model_checkpoint, reduce_lr],\n",
    "                     verbose = 2)\n",
    "t_model1_end = time.time()\n",
    "\n",
    "v={\"tt\":(t_model1_end-t_model1_start)/3600}\n",
    "print(\"Run time = {tt} hours\".format(**v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_loss, ax_score) = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax_loss.legend()\n",
    "ax_score.plot(history.epoch, history.history[\"my_iou_metric_2\"], label=\"Train score\")\n",
    "ax_score.plot(history.epoch, history.history[\"val_my_iou_metric_2\"], label=\"Validation score\")\n",
    "ax_score.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "52ba1ba40cac42145f499cff252eb73feff397d3"
   },
   "outputs": [],
   "source": [
    "model1 = load_model(save_model_name, custom_objects={'my_iou_metric':my_iou_metric})\n",
    "# remove activation layer and use lovasz loss\n",
    "input_x = model1.layers[0].input\n",
    "\n",
    "output_layer = model1.layers[-1].input\n",
    "model = Model(input_x, output_layer)\n",
    "c = optimizers.adam(lr=0.01)\n",
    "\n",
    "model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec1e49fd425a02ab12dea6b99cf39de45c80199f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=30, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=15, \n",
    "                              min_lr=0.00005, verbose=1)\n",
    "epochs = 400\n",
    "batch_size = 64\n",
    "\n",
    "t_model2_start = time.time()\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[ model_checkpoint,reduce_lr,early_stopping], \n",
    "                    verbose=2)\n",
    "t_model2_end = time.time()\n",
    "print(f\"Run time = {(t_model2_end-t_model2_start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "922febde76d7aff93c49c71a28b3a2361f433d02"
   },
   "outputs": [],
   "source": [
    "fig, (ax_loss, ax_score) = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax_loss.legend()\n",
    "ax_score.plot(history.epoch, history.history[\"my_iou_metric_2\"], label=\"Train score\")\n",
    "ax_score.plot(history.epoch, history.history[\"val_my_iou_metric_2\"], label=\"Validation score\")\n",
    "ax_score.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "068c89f56e9e7eb1d7ecf12912996426ad87f2a6"
   },
   "outputs": [],
   "source": [
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "                                                   'lovasz_loss': lovasz_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c33f2cdf50d3011f704ac934e49602bd3167c8cb"
   },
   "outputs": [],
   "source": [
    "def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n",
    "    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n",
    "    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test += np.array([ np.fliplr(x) for x in preds_test2_refect] )\n",
    "    return preds_test/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec38f74adccf2d265cac160311c0998fefc76ec6"
   },
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6794a936dd110f0d4ecc23206c53af7cd0f4a587"
   },
   "outputs": [],
   "source": [
    "#Score the model and do a threshold optimization by the best IoU.\n",
    "\n",
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "\n",
    "\n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n",
    "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
    "#     temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))\n",
    "    #print(temp1)\n",
    "    intersection = temp1[0]\n",
    "    #print(\"temp2 = \",temp1[1])\n",
    "    #print(intersection.shape)\n",
    "   # print(intersection)\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    #print(np.histogram(labels, bins = true_objects))\n",
    "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
    "    #print(\"area_true = \",area_true)\n",
    "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "  \n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    intersection[intersection == 0] = 1e-9\n",
    "    \n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "        \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d96072932f985336021cd115cb6bb13058618a8"
   },
   "outputs": [],
   "source": [
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce197d87cf44fef681025160cba8e4081d15ed50"
   },
   "outputs": [],
   "source": [
    "threshold_best_index = np.argmax(ious)\n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, 'xr', label='Best threshold')\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2633e0c50ddb705021a35441c6a19fae9312603e"
   },
   "outputs": [],
   "source": [
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1-mask, 0-background\n",
    "    Returns run length as string\n",
    "    '''\n",
    "    pixels = im.flatten(order='F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c29b25a37ceb7476bc0264ea3a97dc705e07607"
   },
   "outputs": [],
   "source": [
    "x_test = np.array([(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e129e7c3e525b884322570ed37da825cd89db290"
   },
   "outputs": [],
   "source": [
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aac939d180585abab6dd497a45f81e3df67b25a8"
   },
   "outputs": [],
   "source": [
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d6ef314f368bf9923285007e7098c068af049d9"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae636758e7abdc7fb87768cbfb2c6f18f8c1975f"
   },
   "outputs": [],
   "source": [
    "t_finish = time.time()\n",
    "print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76d50b9d2159775ae3a84336ef0c01cbcf39a18e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
